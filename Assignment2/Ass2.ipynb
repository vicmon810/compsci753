{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0156564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    " # loading data\n",
    "with open('goodreads_reviews_young_adult_train.json', 'r') as f:\n",
    "    training_data = [json.loads(line) for line in f]\n",
    "\n",
    "with open('goodreads_reviews_young_adult_test.json', 'r') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "with open('goodreads_reviews_young_adult_val.json', 'r') as f:\n",
    "    val_data = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(training_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10f76f",
   "metadata": {},
   "source": [
    "# Task 1:Explore biases\n",
    "Calculate the global bias bg, user specific bias b(user)\n",
    "i and item specific bias b(item)\n",
    "j on the\n",
    "training data. Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "562eee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Bias (bg): 3.7634559326052694\n",
      "User Specific Bias (b_user_i) for user '91ceb82d91493506532feb02ce751ce7': -0.9974984857967586\n",
      "Item Specific Bias (b_item_j) for item '6931234': -0.24732690034720495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#(A) The global bg bias\n",
    "global_bias = train_df['rating'].mean()\n",
    "print(f\"Global Bias (bg): {global_bias}\")\n",
    "\n",
    "# (B) User-Specific Bias (b_user_i) 91ceb82d91493506532feb02ce751ce7\n",
    "user_bias = train_df.groupby('user_id')['rating'].mean() - global_bias\n",
    "\n",
    "print(f\"User Specific Bias (b_user_i) for user '91ceb82d91493506532feb02ce751ce7': {user_bias['91ceb82d91493506532feb02ce751ce7']}\")\n",
    "\n",
    "\n",
    "# (C) Item-Specific Bias (b_item_j) 6931234\n",
    "item_bias = train_df.groupby('item_id')['rating'].mean() - global_bias\n",
    "print(f\"Item Specific Bias (b_item_j) for item '6931234': {item_bias['6931234']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa939e9b",
   "metadata": {},
   "source": [
    "# Task 2: Regularized Latent Factor Model Without Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77fa7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing with small case \n",
    "# train_df = train_df[1:100]\n",
    "# test_df = test_df[1:100]\n",
    "# val_df = val_df[1:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883de14e-9d0a-4489-b405-901afbb12bbc",
   "metadata": {},
   "source": [
    "# (A) Implement the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c9bd3d9-25ec-4197-8638-1628f32186af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "num_users = train_df['user_id'].nunique()\n",
    "num_items = train_df['item_id'].nunique()\n",
    "k = 8  # Number of latent factors\n",
    "# Create user and item mappings\n",
    "user_map = {user_id: idx for idx, user_id in enumerate(train_df['user_id'].unique())}\n",
    "item_map = {item_id: idx for idx, item_id in enumerate(train_df['item_id'].unique())}\n",
    "\n",
    "# Initialize latent factor matrices P and Q\n",
    "# P = np.random.normal(scale=1/k, size=(num_users, k))\n",
    "# Q = np.random.normal(scale=1/k, size=(num_items, k))\n",
    "P = np.random.normal(0, 0.1, (num_users,k))\n",
    "Q = np.random.normal(0, 0.1, (num_items,k))\n",
    "\n",
    "# Set SGD hyperparameters\n",
    "learning_rate = 0.01\n",
    "lambda_reg = 0.3\n",
    "epochs = 10\n",
    "\n",
    "# SGD training\n",
    "train_errors = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3a88985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training RMSE = 3.7505610651244297\n",
      "Epoch 2: Training RMSE = 2.6503636110386704\n",
      "Epoch 3: Training RMSE = 2.223193726480888\n",
      "Epoch 4: Training RMSE = 1.9783919265263685\n",
      "Epoch 5: Training RMSE = 1.811568123377354\n",
      "Epoch 6: Training RMSE = 1.6883776034265505\n",
      "Epoch 7: Training RMSE = 1.5930787086208438\n",
      "Epoch 8: Training RMSE = 1.5169876781386962\n",
      "Epoch 9: Training RMSE = 1.4547805745084432\n",
      "Epoch 10: Training RMSE = 1.4029569324554707\n"
     ]
    }
   ],
   "source": [
    "# SDG loop\n",
    "for epoch in range(epochs):\n",
    "    for index, row in train_df.iterrows():\n",
    "        user_idx = user_map[row['user_id']]\n",
    "        item_idx = item_map[row['item_id']]\n",
    "        rating = row['rating']\n",
    "        \n",
    "        # Predict rating\n",
    "        pred = np.dot(P[user_idx], Q[item_idx])\n",
    "        \n",
    "        # Calculate error\n",
    "        error = rating - pred\n",
    "        \n",
    "        # Update latent factors\n",
    "        P[user_idx] += learning_rate * (error * Q[item_idx] - lambda_reg * P[user_idx])\n",
    "        Q[item_idx] += learning_rate * (error * P[user_idx] - lambda_reg * Q[item_idx])\n",
    "    \n",
    "    # Calculate RMSE for the epoch\n",
    "    train_preds = train_df.apply(lambda row: np.dot(P[user_map[row['user_id']]], Q[item_map[row['item_id']]]), axis=1)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_df['rating'], train_preds))\n",
    "    train_errors.append(train_rmse)\n",
    "    print(f'Epoch {epoch+1}: Training RMSE = {train_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de07809-4f45-4d60-a28b-cd5d919d7b21",
   "metadata": {},
   "source": [
    "# (B) Evaluate on Validation and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df068af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for k=4...\n",
      "Epoch 1: Validation RMSE (k=4) = 3.786554764384929\n",
      "Epoch 2: Validation RMSE (k=4) = 2.7157270218375205\n",
      "Epoch 3: Validation RMSE (k=4) = 2.3081480446775196\n",
      "Epoch 4: Validation RMSE (k=4) = 2.0776809498956985\n",
      "Epoch 5: Validation RMSE (k=4) = 1.9213612445192276\n",
      "Epoch 6: Validation RMSE (k=4) = 1.8063130866120114\n",
      "Epoch 7: Validation RMSE (k=4) = 1.7177995871565068\n",
      "Epoch 8: Validation RMSE (k=4) = 1.647583782747846\n",
      "Epoch 9: Validation RMSE (k=4) = 1.5905617271315184\n",
      "Epoch 10: Validation RMSE (k=4) = 1.5434482268149905\n",
      "Training for k=8...\n",
      "Epoch 1: Validation RMSE (k=8) = 3.6922550616223613\n",
      "Epoch 2: Validation RMSE (k=8) = 2.67867641082997\n",
      "Epoch 3: Validation RMSE (k=8) = 2.2903563188856046\n",
      "Epoch 4: Validation RMSE (k=8) = 2.0667460527454025\n",
      "Epoch 5: Validation RMSE (k=8) = 1.9138029637694876\n",
      "Epoch 6: Validation RMSE (k=8) = 1.80086743675591\n",
      "Epoch 7: Validation RMSE (k=8) = 1.7138030895051817\n",
      "Epoch 8: Validation RMSE (k=8) = 1.6446126199721023\n",
      "Epoch 9: Validation RMSE (k=8) = 1.5883922768758005\n",
      "Epoch 10: Validation RMSE (k=8) = 1.5419543704366832\n",
      "Training for k=16...\n",
      "Epoch 1: Validation RMSE (k=16) = 3.677722269740353\n",
      "Epoch 2: Validation RMSE (k=16) = 2.6653785656863533\n",
      "Epoch 3: Validation RMSE (k=16) = 2.2785933386424717\n",
      "Epoch 4: Validation RMSE (k=16) = 2.056759211984615\n",
      "Epoch 5: Validation RMSE (k=16) = 1.9058125527294447\n",
      "Epoch 6: Validation RMSE (k=16) = 1.7947539195409816\n",
      "Epoch 7: Validation RMSE (k=16) = 1.7093292098330954\n",
      "Epoch 8: Validation RMSE (k=16) = 1.6415615684777378\n",
      "Epoch 9: Validation RMSE (k=16) = 1.58658136817198\n",
      "Epoch 10: Validation RMSE (k=16) = 1.5412187377830395\n",
      "Best k = 16, Validation RMSE = 1.5412187377830395\n",
      "Test RMSE with the best k=16: 1.5503744539240147\n"
     ]
    }
   ],
   "source": [
    "#(B) Evaluate on Validation and Test Sets\n",
    "def train_and_evaluate(k):\n",
    "    P = np.random.normal(0, 0.1,size = (num_users,k))\n",
    "    Q = np.random.normal(0, 0.1,size =  (num_items,k))\n",
    "    train_errors = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for index, row in train_df.iterrows():\n",
    "            user_idx = user_map[row['user_id']]\n",
    "            item_idx = item_map[row['item_id']]\n",
    "            rating = row['rating']\n",
    "\n",
    "            # Predict rating\n",
    "            pred = np.dot(P[user_idx], Q[item_idx])\n",
    "\n",
    "            # Calculate error\n",
    "            error = rating - pred\n",
    "\n",
    "            # Update latent factors\n",
    "            P[user_idx] += learning_rate * (error * Q[item_idx] - lambda_reg * P[user_idx])\n",
    "            Q[item_idx] += learning_rate * (error * P[user_idx] - lambda_reg * Q[item_idx])\n",
    "\n",
    "        # Calculate RMSE on validation data\n",
    "        val_preds = val_df.apply(lambda row: np.dot(P[user_map.get(row['user_id'], 0)], Q[item_map.get(row['item_id'], 0)]), axis=1)\n",
    "        val_rmse = np.sqrt(mean_squared_error(val_df['rating'], val_preds))\n",
    "        train_errors.append(val_rmse)\n",
    "        print(f'Epoch {epoch+1}: Validation RMSE (k={k}) = {val_rmse}')\n",
    "\n",
    "    return train_errors[-1]\n",
    "\n",
    "# Train for k = 4, 8, 16 and select the best model\n",
    "best_k = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for k in [4, 8, 16]:\n",
    "    print(f'Training for k={k}...')\n",
    "    val_rmse = train_and_evaluate(k)\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_k = k\n",
    "\n",
    "print(f'Best k = {best_k}, Validation RMSE = {best_rmse}')\n",
    "\n",
    "# Test on the test data with the best k\n",
    "def evaluate_on_test(P, Q):\n",
    "    # Calculate RMSE on the test data\n",
    "    test_preds = test_df.apply(lambda row: np.dot(P[user_map.get(row['user_id'], 0)], Q[item_map.get(row['item_id'], 0)]), axis=1)\n",
    "    test_rmse = np.sqrt(mean_squared_error(test_df['rating'], test_preds))\n",
    "    return test_rmse\n",
    "\n",
    "# Re-train with the best k found\n",
    "P = np.random.normal(0, 0.1, size=(num_users, best_k))\n",
    "Q = np.random.normal(0, 0.1, size=(num_items, best_k))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for index, row in train_df.iterrows():\n",
    "        user_idx = user_map[row['user_id']]\n",
    "        item_idx = item_map[row['item_id']]\n",
    "        rating = row['rating']\n",
    "\n",
    "        # Predict rating\n",
    "        pred = np.dot(P[user_idx], Q[item_idx])\n",
    "\n",
    "        # Calculate error\n",
    "        error = rating - pred\n",
    "\n",
    "        # Update latent factors\n",
    "        P[user_idx] += learning_rate * (error * Q[item_idx] - lambda_reg * P[user_idx])\n",
    "        Q[item_idx] += learning_rate * (error * P[user_idx] - lambda_reg * Q[item_idx])\n",
    "\n",
    "# Evaluate on the test data\n",
    "test_rmse = evaluate_on_test(P, Q)\n",
    "print(f'Test RMSE with the best k={best_k}: {test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abef29",
   "metadata": {},
   "source": [
    "# Task 3: Regularized Latent Factor Model With Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823fe8fd-c9ae-4755-842a-ac5088e8bb08",
   "metadata": {},
   "source": [
    "# (A) Incorporate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4235f5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training RMSE with Bias = 0.9657341991065203\n",
      "Epoch 2: Training RMSE with Bias = 0.9635950206124181\n",
      "Epoch 3: Training RMSE with Bias = 0.9622577189919499\n",
      "Epoch 4: Training RMSE with Bias = 0.9612737390774274\n",
      "Epoch 5: Training RMSE with Bias = 0.9604982965547415\n",
      "Epoch 6: Training RMSE with Bias = 0.9598619443473199\n",
      "Epoch 7: Training RMSE with Bias = 0.9593249481274763\n",
      "Epoch 8: Training RMSE with Bias = 0.9588622432811763\n",
      "Epoch 9: Training RMSE with Bias = 0.958456965603243\n",
      "Epoch 10: Training RMSE with Bias = 0.958097216835294\n"
     ]
    }
   ],
   "source": [
    "# (A) Incorporate Bias\n",
    "\n",
    "# Initialize bias terms\n",
    "b_user = user_bias.to_dict()\n",
    "b_item = item_bias.to_dict()\n",
    "\n",
    "# Initialize P, Q, and re-use b_user and b_item\n",
    "P = np.random.normal(0, 0.1, size=(num_users, k))\n",
    "Q = np.random.normal(0, 0.1, size=(num_items, k))\n",
    "# Update SGD to include bias\n",
    "for epoch in range(epochs):\n",
    "    for index, row in train_df.iterrows():\n",
    "        user_idx = user_map[row['user_id']]\n",
    "        item_idx = item_map[row['item_id']]\n",
    "        rating = row['rating']\n",
    "        \n",
    "        # Predict rating including biases\n",
    "        pred = global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_idx], Q[item_idx])\n",
    "        \n",
    "        # Calculate error\n",
    "        error = rating - pred\n",
    "        \n",
    "        # Update latent factors\n",
    "        P[user_idx] += learning_rate * (error * Q[item_idx] - lambda_reg * P[user_idx])\n",
    "        Q[item_idx] += learning_rate * (error * P[user_idx] - lambda_reg * Q[item_idx])\n",
    "        \n",
    "        # Update biases\n",
    "        b_user[row['user_id']] = b_user.get(row['user_id'], 0) + learning_rate * (error - lambda_reg * b_user.get(row['user_id'], 0))\n",
    "        b_item[row['item_id']] = b_item.get(row['item_id'], 0) + learning_rate * (error - lambda_reg * b_item.get(row['item_id'], 0))\n",
    "    \n",
    "    # Calculate RMSE for the epoch\n",
    "    train_preds = train_df.apply(lambda row: global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_map[row['user_id']]], Q[item_map[row['item_id']]]), axis=1)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_df['rating'], train_preds))\n",
    "    print(f'Epoch {epoch+1}: Training RMSE with Bias = {train_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1e3d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned user-specific bias for user '91ceb82d91493506532feb02ce751ce7': -0.5928744612577722\n",
      "Learned item-specific bias for item '6931234': -0.1953191661901935\n"
     ]
    }
   ],
   "source": [
    "# After training the model, get the learned biases for the specific user and item\n",
    "user_id = \"91ceb82d91493506532feb02ce751ce7\"\n",
    "item_id = \"6931234\"\n",
    "\n",
    "learned_user_bias = b_user.get(user_id, 0)\n",
    "learned_item_bias = b_item.get(item_id, 0)\n",
    "\n",
    "print(f\"Learned user-specific bias for user '{user_id}': {learned_user_bias}\")\n",
    "print(f\"Learned item-specific bias for item '{item_id}': {learned_item_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d70a666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Bias for k=4...\n",
      "Epoch 1: Training RMSE (k=4) = 0.966552850813979, Validation RMSE (k=4) = 1.1514363187253567\n",
      "Epoch 2: Training RMSE (k=4) = 0.9648707444055573, Validation RMSE (k=4) = 1.1491906106678165\n",
      "Epoch 3: Training RMSE (k=4) = 0.9637925628087926, Validation RMSE (k=4) = 1.1472804049374712\n",
      "Epoch 4: Training RMSE (k=4) = 0.9629781322351195, Validation RMSE (k=4) = 1.145614041398226\n",
      "Epoch 5: Training RMSE (k=4) = 0.9623229711882263, Validation RMSE (k=4) = 1.1441364370072569\n",
      "Epoch 6: Training RMSE (k=4) = 0.9617768523434768, Validation RMSE (k=4) = 1.1428089737280727\n",
      "Epoch 7: Training RMSE (k=4) = 0.961310566673417, Validation RMSE (k=4) = 1.1416037540416124\n",
      "Epoch 8: Training RMSE (k=4) = 0.9609053555502296, Validation RMSE (k=4) = 1.1405001286126786\n",
      "Epoch 9: Training RMSE (k=4) = 0.9605483821355886, Validation RMSE (k=4) = 1.1394824243431567\n",
      "Epoch 10: Training RMSE (k=4) = 0.9602304479540755, Validation RMSE (k=4) = 1.1385384616666023\n",
      "Training with Bias for k=8...\n",
      "Epoch 1: Training RMSE (k=8) = 0.9662887358768631, Validation RMSE (k=8) = 1.151488442387574\n",
      "Epoch 2: Training RMSE (k=8) = 0.9644487301617809, Validation RMSE (k=8) = 1.14922653482598\n",
      "Epoch 3: Training RMSE (k=8) = 0.9632820876957221, Validation RMSE (k=8) = 1.1473095302178207\n",
      "Epoch 4: Training RMSE (k=8) = 0.9624102815084385, Validation RMSE (k=8) = 1.145639087236424\n",
      "Epoch 5: Training RMSE (k=8) = 0.9617146467444893, Validation RMSE (k=8) = 1.1441586355415945\n",
      "Epoch 6: Training RMSE (k=8) = 0.9611382436337624, Validation RMSE (k=8) = 1.142829043175391\n",
      "Epoch 7: Training RMSE (k=8) = 0.960648233576507, Validation RMSE (k=8) = 1.141622179728745\n",
      "Epoch 8: Training RMSE (k=8) = 0.9602237108378866, Validation RMSE (k=8) = 1.1405172681515743\n",
      "Epoch 9: Training RMSE (k=8) = 0.9598504811692806, Validation RMSE (k=8) = 1.1394985546654857\n",
      "Epoch 10: Training RMSE (k=8) = 0.95951844263727, Validation RMSE (k=8) = 1.138553803147319\n",
      "Training with Bias for k=16...\n",
      "Epoch 1: Training RMSE (k=16) = 0.9657009309180452, Validation RMSE (k=16) = 1.1516424147558562\n",
      "Epoch 2: Training RMSE (k=16) = 0.9635598160277281, Validation RMSE (k=16) = 1.1493400008147112\n",
      "Epoch 3: Training RMSE (k=16) = 0.9622240512581692, Validation RMSE (k=16) = 1.1474007344853334\n",
      "Epoch 4: Training RMSE (k=16) = 0.9612430411838054, Validation RMSE (k=16) = 1.145716304565483\n",
      "Epoch 5: Training RMSE (k=16) = 0.9604707546682398, Validation RMSE (k=16) = 1.144226315077616\n",
      "Epoch 6: Training RMSE (k=16) = 0.9598372899262566, Validation RMSE (k=16) = 1.1428898786252153\n",
      "Epoch 7: Training RMSE (k=16) = 0.9593027827487167, Validation RMSE (k=16) = 1.141677929772454\n",
      "Epoch 8: Training RMSE (k=16) = 0.9588421570176491, Validation RMSE (k=16) = 1.1405691372740676\n",
      "Epoch 9: Training RMSE (k=16) = 0.9584385759544591, Validation RMSE (k=16) = 1.1395473948417312\n",
      "Epoch 10: Training RMSE (k=16) = 0.9580801782739203, Validation RMSE (k=16) = 1.1386002314151678\n",
      "Best k with Bias = 4, Validation RMSE = 1.1385384616666023\n"
     ]
    }
   ],
   "source": [
    "# (B) Evaluate on Validation and Test Sets\n",
    "# Define the function to train and evaluate the model with bias\n",
    "def train_and_evaluate_with_bias(k):\n",
    "    # Initialize P, Q, and biases\n",
    "    P = np.random.normal(0, 0.1, size=(num_users, k))\n",
    "    Q = np.random.normal(0, 0.1, size=(num_items, k))\n",
    "    b_user = user_bias.to_dict()\n",
    "    b_item = item_bias.to_dict()\n",
    "    \n",
    "    train_rmse_list = []\n",
    "    val_rmse_list = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for index, row in train_df.iterrows():\n",
    "            user_idx = user_map[row['user_id']]\n",
    "            item_idx = item_map[row['item_id']]\n",
    "            rating = row['rating']\n",
    "\n",
    "            # Predict rating including biases\n",
    "            pred = global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_idx], Q[item_idx])\n",
    "\n",
    "            # Calculate error\n",
    "            error = rating - pred\n",
    "\n",
    "            # Update latent factors\n",
    "            P[user_idx] += learning_rate * (error * Q[item_idx] - lambda_reg * P[user_idx])\n",
    "            Q[item_idx] += learning_rate * (error * P[user_idx] - lambda_reg * Q[item_idx])\n",
    "\n",
    "            # Update biases\n",
    "            b_user[row['user_id']] = b_user.get(row['user_id'], 0) + learning_rate * (error - lambda_reg * b_user.get(row['user_id'], 0))\n",
    "            b_item[row['item_id']] = b_item.get(row['item_id'], 0) + learning_rate * (error - lambda_reg * b_item.get(row['item_id'], 0))\n",
    "\n",
    "        # Calculate RMSE on the training data\n",
    "        train_preds = train_df.apply(lambda row: global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_map[row['user_id']]], Q[item_map[row['item_id']]]), axis=1)\n",
    "        train_rmse = np.sqrt(mean_squared_error(train_df['rating'], train_preds))\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        \n",
    "        # Calculate RMSE on the validation data\n",
    "        val_preds = val_df.apply(lambda row: global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_map.get(row['user_id'], 0)], Q[item_map.get(row['item_id'], 0)]), axis=1)\n",
    "        val_rmse = np.sqrt(mean_squared_error(val_df['rating'], val_preds))\n",
    "        val_rmse_list.append(val_rmse)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Training RMSE (k={k}) = {train_rmse}, Validation RMSE (k={k}) = {val_rmse}')\n",
    "    \n",
    "    return train_rmse_list, val_rmse_list\n",
    "\n",
    "# Train for k = 4, 8, 16 and select the best model\n",
    "best_k_with_bias = None\n",
    "best_val_rmse_with_bias = float('inf')\n",
    "\n",
    "for k in [4, 8, 16]:\n",
    "    print(f'Training with Bias for k={k}...')\n",
    "    train_rmse_list, val_rmse_list = train_and_evaluate_with_bias(k)\n",
    "    final_val_rmse = val_rmse_list[-1]\n",
    "    \n",
    "    if final_val_rmse < best_val_rmse_with_bias:\n",
    "        best_val_rmse_with_bias = final_val_rmse\n",
    "        best_k_with_bias = k\n",
    "\n",
    "print(f'Best k with Bias = {best_k_with_bias}, Validation RMSE = {best_val_rmse_with_bias}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82fb748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE with Bias = 1.1359763303486203\n"
     ]
    }
   ],
   "source": [
    "# (B) Evaluate the Best Model on the Test Set\n",
    "\n",
    "# Use the best k found with bias to evaluate on the test set\n",
    "P = np.random.normal(scale=1/best_k_with_bias, size=(num_users, best_k_with_bias))\n",
    "Q = np.random.normal(scale=1/best_k_with_bias, size=(num_items, best_k_with_bias))\n",
    "b_user = user_bias.to_dict()\n",
    "b_item = item_bias.to_dict()\n",
    "\n",
    "# Retrain the model using the best k\n",
    "for epoch in range(epochs):\n",
    "    for index, row in train_df.iterrows():\n",
    "        user_idx = user_map[row['user_id']]\n",
    "        item_idx = item_map[row['item_id']]\n",
    "        rating = row['rating']\n",
    "\n",
    "        # Predict rating including biases\n",
    "        pred = global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_idx], Q[item_idx])\n",
    "\n",
    "        # Calculate error\n",
    "        error = rating - pred\n",
    "\n",
    "        # Update latent factors\n",
    "        P[user_idx] += learning_rate * (error * Q[item_idx] - lambda_reg * P[user_idx])\n",
    "        Q[item_idx] += learning_rate * (error * P[user_idx] - lambda_reg * Q[item_idx])\n",
    "\n",
    "        # Update biases\n",
    "        b_user[row['user_id']] = b_user.get(row['user_id'], 0) + learning_rate * (error - lambda_reg * b_user.get(row['user_id'], 0))\n",
    "        b_item[row['item_id']] = b_item.get(row['item_id'], 0) + learning_rate * (error - lambda_reg * b_item.get(row['item_id'], 0))\n",
    "\n",
    "# Evaluate on the test data\n",
    "test_preds = test_df.apply(lambda row: global_bias + b_user.get(row['user_id'], 0) + b_item.get(row['item_id'], 0) + np.dot(P[user_map.get(row['user_id'], 0)], Q[item_map.get(row['item_id'], 0)]), axis=1)\n",
    "test_rmse_with_bias = np.sqrt(mean_squared_error(test_df['rating'], test_preds))\n",
    "\n",
    "print(f'Test RMSE with Bias = {test_rmse_with_bias}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbf494-7d7b-4f27-b73d-892e59103f38",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "    \n",
    "Task 2 (A) : From the obersvation we can discover the RMSE have significant chages through epochs from 3.81 drop down to 1.40 which indicates the model are able to learn user-item interactions and reduce prediction errors effectively over time.\n",
    "\n",
    "Task 2 (B) : In the term of varying k increase the RMSE decrease accordingly as following <br>\n",
    "- k = 4 : RMSE drop 3.783 to 1.543 over 10 epochs \n",
    "- k = 8 : RMSE drop 3.818 to 1.542 over 10 epochs\n",
    "- k = 16 : RMSE drop 3.643 to 1.541 over 10 epochs\n",
    "As the result the best fit k is when k equals 16 with best performance of RMSE with 1.541.\n",
    "\n",
    "\n",
    "Task 3 (A): Following many cycles, the RMSE dropped from 0.9657 to 0.9580. Nonetheless, the RMSE decrease was not substantial, suggesting that the model's performance did not increase during the epochs. This implies that more training is producing diminishing rewards in terms of lowering prediction error, and that the model may have converged.\n",
    "\n",
    "\n",
    "\n",
    "Task 3 (B) : On the train side the highest K value have the best performance(RMSE = 0.985 when k =16), however in the validation term the smallest k value actually has the best performance(RMSE = 1.138527 when k =4).\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "Task 2: The model without bias performed quite well, as predicted, with the validation RMSE dropping for all values of k. However, in comparison to the model with bias, its final RMSEs remained rather high. For k=16, the best validation RMSE was 1.541.\n",
    "\n",
    "\n",
    "Task 3: By adding bias terms (global, user-specific, and item-specific biases), performance significantly improved. Task 3's training RMSEs were consistently lower than Task 2's, suggesting that the model may provide a better fit for the data. Consistent improvement was also seen in the validation RMSE; for k=4, the best RMSE was 1.138, as opposed to 1.541 in Task 2.\n",
    "\n",
    "\n",
    "## Choice of K\n",
    "\n",
    "With a greater number of latent components (k=16) in Task 2, the bias-free model outperformed the others, while in Task 3, the optimal model had fewer latent elements (k=4).\n",
    "This shows that the model requires fewer latent features to accurately describe the interactions between users and objects after bias words are incorporated. Some of the variability that would normally need more latent components in the model without bias is captured by bias terms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
